"0","ridge <- function(w, X, y, lambda = .1) {"
"0","  # X: model matrix; "
"0","  # y: target; "
"0","  # lambda: penalty parameter; "
"0","  # w: the weights/coefficients"
"0","  "
"0","  crossprod(y - X %*% w) + lambda * length(y) * crossprod(w)"
"0","}"
"0",""
"0",""
"0","set.seed(8675309)"
"0","N = 500"
"0","p = 10"
"0","X = scale(matrix(rnorm(N * p), ncol = p))"
"0","b = c(.5, -.5, .25, -.25, .125, -.125, rep(0, 4))"
"0","y = scale(X %*% b + rnorm(N, sd = .5))"
"0",""
"0","#' Note, if `lambda=0`, result is the same as  `lm.fit`."
"0","#' "
"0","#' "
"0","result_ridge = optim("
"0","  rep(0, ncol(X)),"
"0","  ridge,"
"0","  X = X,"
"0","  y = y,"
"0","  lambda = .1,"
"0","  method = 'BFGS'"
"0",")"
"0",""
"0","#' Analytical result."
"0","#' "
"0","result_ridge2 =  solve(crossprod(X) + diag(length(y)*.1, ncol(X))) %*% crossprod(X, y)"
"0",""
"0","#' Alternative with augmented data (note sigma ignored as it equals 1, but otherwise"
"0","#' X/sigma and y/sigma)."
"0","#' "
"0","X2 = rbind(X, diag(sqrt(length(y)*.1), ncol(X)))"
"0","y2 = c(y, rep(0, ncol(X)))"
"0","result_ridge3 = solve(crossprod(X2)) %*% crossprod(X2, y2)"
"0",""
"0",""
"0",""
"0",""
"0","#' `glmnet` is by default a mixture of ridge and lasso penalties, setting alpha"
"0","#' = 1 reduces to lasso, while alpha=0 would be ridge."
"0",""
"0",""
"0","library(glmnet)"
"0","glmnet_res = coef("
"0","  glmnet("
"0","    X,"
"0","    y,"
"0","    alpha = 0,"
"0","    lambda = c(10, 1, .1),"
"0","    thresh = 1e-12,"
"0","    intercept = F"
"0","  ), "
"0","  s = .1"
"0",")"
"0",""
"0","#' # Comparison"
"0",""
"0","data.frame("
"0","  lm     = coef(lm(y ~ . - 1, data.frame(X))),"
"0","  ridge  = result_ridge$par,"
"0","  ridge2 = result_ridge2,"
"0","  ridge3 = result_ridge3,"
"0","  glmnet = glmnet_res[-1, 1],"
"0","  truth  = b"
"0",")"
