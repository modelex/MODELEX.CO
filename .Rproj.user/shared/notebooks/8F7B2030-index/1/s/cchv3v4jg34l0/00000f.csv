"0","set.seed(1235)  # ensures replication"
"0",""
"0",""
"0","# predictors and target"
"0",""
"0","N = 10000 # sample size"
"0","k = 2     # number of desired predictors"
"0","X = matrix(rnorm(N * k), ncol = k)"
"0",""
"0","# the linear predictor"
"0","lp = -.5 + .2 * X[, 1] + .1 * X[, 2] # increasing N will get estimated values closer to these"
"0",""
"0","y = rbinom(N, size = 1, prob = plogis(lp))"
"0",""
"0","dfXy = data.frame(X, y)"
"0",""
"0",""
"0",""
"0","#' "
"0","#' # Functions "
"0","#' "
"0","#' A maximum likelihood approach."
"0",""
"0","logreg_ML = function(par, X, y) {"
"0","  # arguments- "
"0","  # par: parameters to be estimated"
"0","  # X: predictor matrix with intercept column"
"0","  # y: response"
"0","  "
"0","  # setup"
"0","  beta = par                                # coefficients"
"0","  N = nrow(X)"
"0","  "
"0","  # linear predictor"
"0","  LP = X %*% beta                           # linear predictor"
"0","  mu = plogis(LP)                           # logit link"
"0","  "
"0","  # calculate likelihood"
"0","  L = dbinom(y, size = 1, prob = mu, log = TRUE)         # log likelihood"
"0","  #   L =  y*log(mu) + (1 - y)*log(1-mu)    # alternate log likelihood form"
"0","  "
"0","  -sum(L)                                   # optim by default is minimization, and we want to maximize the likelihood "
"0","  # (see also fnscale in optim.control)"
"0","}"
"0",""
"0","# An equivalent approach via exponential loss function."
"0",""
"0","logreg_exp = function(par, X, y) {"
"0","  # arguments- "
"0","  # par: parameters to be estimated"
"0","  # X: predictor matrix with intercept column"
"0","  # y: response"
"0","  "
"0","  # setup"
"0","  beta = par                                   # coefficients"
"0","  "
"0","  # linear predictor"
"0","  LP = X %*% beta                              # linear predictor"
"0",""
"0","  # calculate exponential loss function (convert y to -1:1 from 0:1)"
"0","  L = sum(exp(-ifelse(y, 1, -1) * .5 * LP))"
"0","}"
"0",""
"0",""
"0","#' # Obtain Model Estimates"
"0","#' Setup for use with `optim`."
"0",""
"0","X = cbind(1, X)"
"0",""
"0","# initial values"
"0",""
"0","init = rep(0, ncol(X))"
"0","names(init) = c('intercept', 'b1', 'b2')"
"0",""
"0","optlmML = optim("
"0","  par = init,"
"0","  fn  = logreg_ML,"
"0","  X   = X,"
"0","  y   = y,"
"0","  control = list(reltol = 1e-8)"
"0",")"
"0",""
"0","optglmClass = optim("
"0","  par = init,"
"0","  fn  = logreg_exp,"
"0","  X   = X,"
"0","  y   = y, "
"0","  control = list(reltol = 1e-15)"
"0",")"
"0",""
"0","pars_ML  = optlmML$par"
"0","pars_exp = optglmClass$par"
"0",""
"0",""
"0","#' # Comparison"
"0","#' "
"0","#' Compare to `glm`."
"0",""
"0","modglm = glm(y ~ ., dfXy, family = binomial)"
"0",""
"0","rbind("
"0","  pars_ML,"
"0","  pars_exp,"
"0","  pars_GLM = coef(modglm)"
"0",")"
"1","        "
"1","  intercept"
"1","        b1"
"1","         b2"
"1","
pars_ML "
"1"," -0.5117658"
"1"," 0.2378927"
"1"," 0.08019841"
"1","
pars_exp"
"1"," -0.5114284"
"1"," 0.2368478"
"1"," 0.07907056"
"1","
pars_GLM"
"1"," -0.5117321"
"1"," 0.2378743"
"1"," 0.08032617"
"1","
"
