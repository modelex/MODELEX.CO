"0","nelder_mead = function("
"0","  f, "
"0","  x_start,"
"0","  step = 0.1,"
"0","  no_improve_thr  = 1e-12,"
"0","  no_improv_break = 10,"
"0","  max_iter = 0,"
"0","  alpha    = 1,"
"0","  gamma    = 2,"
"0","  rho      = 0.5,"
"0","  sigma    = 0.5,"
"0","  verbose  = FALSE"
"0","  ) {"
"0","  # init"
"0","  dim = length(x_start)"
"0","  prev_best = f(x_start)"
"0","  no_improv = 0"
"0","  res = list(list(x_start = x_start, prev_best = prev_best))"
"0","  "
"0","  "
"0","  for (i in 1:dim) {"
"0","    x = x_start"
"0","    x[i]  = x[i] + step"
"0","    score = f(x)"
"0","    res = append(res, list(list(x_start = x, prev_best = score)))"
"0","  }"
"0","  "
"0","  # simplex iter"
"0","  iters = 0"
"0","  "
"0","  while (TRUE) {"
"0","    # order"
"0","    idx  = sapply(res, `[[`, 2)"
"0","    res  = res[order(idx)]   # ascending order"
"0","    best = res[[1]][[2]]"
"0","    "
"0","    # break after max_iter"
"0","    if (max_iter > 0 & iters >= max_iter) return(res[[1]])"
"0","    iters = iters + 1"
"0","    "
"0","    # break after no_improv_break iterations with no improvement"
"0","    if (verbose) message(paste('...best so far:', best))"
"0","    "
"0","    if (best < (prev_best - no_improve_thr)) {"
"0","      no_improv = 0"
"0","      prev_best = best"
"0","    } else {"
"0","      no_improv = no_improv + 1"
"0","    }"
"0","    "
"0","    if (no_improv >= no_improv_break) return(res[[1]])"
"0","    "
"0","    # centroid"
"0","    x0 = rep(0, dim)"
"0","    for (tup in 1:(length(res)-1)) {"
"0","      for (i in 1:dim) {"
"0","        x0[i] = x0[i] + res[[tup]][[1]][i] / (length(res)-1)"
"0","      }"
"0","    }"
"0","    "
"0","   # reflection"
"0","   xr = x0 + alpha * (x0 - res[[length(res)]][[1]])"
"0","   rscore = f(xr)"
"0","   if (res[[1]][[2]] <= rscore & "
"0","       rscore < res[[length(res)-1]][[2]]) {"
"0","     res[[length(res)]] = list(xr, rscore)"
"0","     next"
"0","   }"
"0","     "
"0","   # expansion"
"0","   if (rscore < res[[1]][[2]]) {"
"0","     # xe = x0 + gamma*(x0 - res[[length(res)]][[1]])   # issue with this"
"0","     xe = x0 + gamma * (xr - x0)   "
"0","     escore = f(xe)"
"0","     if (escore < rscore) {"
"0","       res[[length(res)]] = list(xe, escore)"
"0","       next"
"0","     } else {"
"0","       res[[length(res)]] = list(xr, rscore)"
"0","       next"
"0","     }"
"0","   }"
"0","   "
"0","   # contraction"
"0","   # xc = x0 + rho*(x0 - res[[length(res)]][[1]])  # issue with wiki consistency for rho values (and optim)"
"0","   xc = x0 + rho * (res[[length(res)]][[1]] - x0)"
"0","   cscore = f(xc)"
"0","   if (cscore < res[[length(res)]][[2]]) {"
"0","     res[[length(res)]] = list(xc, cscore)"
"0","     next"
"0","   }"
"0","   "
"0","   # reduction"
"0","   x1   = res[[1]][[1]]"
"0","   nres = list()"
"0","   for (tup in res) {"
"0","     redx  = x1 + sigma * (tup[[1]] - x1)"
"0","     score = f(redx)"
"0","     nres  = append(nres, list(list(redx, score)))"
"0","   }"
"0","   "
"0","   res = nres"
"0","  }"
"0","}"
"0",""
"0",""
"0",""
"0",""
"0","#' ## Example"
"0","#' The function to minimize."
"0","#' "
"0","f = function(x) {"
"0","  sin(x[1]) * cos(x[2]) * (1 / (abs(x[3]) + 1))"
"0","}"
"0",""
"0","nelder_mead("
"0","  f, "
"0","  c(0, 0, 0), "
"0","  max_iter = 1000, "
"0","  no_improve_thr = 1e-12"
"0",")"
"1","[[1]]
"
"1","[1]"
"1"," -1.570797e+00"
"1"," -2.235577e-07"
"1","  1.637460e-14"
"1","
"
"1","
"
"1","[[2]]
"
"1","[1]"
"1"," -1"
"1","
"
"1","
"
"0","#' Compare to `optimx`.  You may see warnings."
"0","optimx::optimx("
"0","  par = c(0, 0, 0),"
"0","  fn = f,"
"0","  method = ""Nelder-Mead"","
"0","  control = list("
"0","    alpha = 1,"
"0","    gamma = 2,"
"0","    beta = 0.5,"
"0","    maxit = 1000,"
"0","    reltol = 1e-12"
"0","  )"
"0",")"
"2","Avis : no non-missing arguments to max; returning -Inf"
"2","Avis : no non-missing arguments to min; returning Inf"
