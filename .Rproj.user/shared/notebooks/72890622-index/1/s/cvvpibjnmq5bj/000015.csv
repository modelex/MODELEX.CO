"0",""
"0",""
"0",""
"0","#' # Second version"
"0","#' "
"0","#' This is a more natural R approach in my opinion."
"0",""
"0","nelder_mead2 = function("
"0","  f,"
"0","  x_start,"
"0","  step = 0.1,"
"0","  no_improve_thr  = 1e-12,"
"0","  no_improv_break = 10,"
"0","  max_iter = 0,"
"0","  alpha = 1,"
"0","  gamma = 2,"
"0","  rho   = 0.5,"
"0","  sigma = 0.5,"
"0","  verbose = FALSE"
"0",") {"
"0","  "
"0","  # init"
"0","  npar = length(x_start)"
"0","  nc = npar + 1"
"0","  prev_best = f(x_start)"
"0","  no_improv = 0"
"0","  res = matrix(c(x_start, prev_best), ncol = nc)"
"0","  colnames(res) = c(paste('par', 1:npar, sep = '_'), 'score')"
"0","  "
"0","  for (i in 1:npar) {"
"0","    x     = x_start"
"0","    x[i]  = x[i] + step"
"0","    score = f(x)"
"0","    res   = rbind(res, c(x, score))"
"0","  }"
"0","  "
"0","  # simplex iter"
"0","  iters = 0"
"0","  "
"0","  while (TRUE) {"
"0","    # order"
"0","    res  = res[order(res[, nc]), ]   # ascending order"
"0","    best = res[1, nc]"
"0","    "
"0","    # break after max_iter"
"0","    if (max_iter & iters >= max_iter) return(res[1, ])"
"0","    iters = iters + 1"
"0","    "
"0","    # break after no_improv_break iterations with no improvement"
"0","    if (verbose) message(paste('...best so far:', best))"
"0","    "
"0","    if (best < (prev_best - no_improve_thr)) {"
"0","      no_improv = 0"
"0","      prev_best = best"
"0","    } else {"
"0","      no_improv = no_improv + 1"
"0","    }"
"0","    "
"0","    if (no_improv >= no_improv_break)"
"0","      return(res[1, ])"
"0","    "
"0","    nr = nrow(res)"
"0","    "
"0","    # centroid: more efficient than previous double loop"
"0","    x0 = colMeans(res[(1:npar), -nc])"
"0","    "
"0","    # reflection"
"0","    xr = x0 + alpha * (x0 - res[nr, -nc])"
"0","    "
"0","    rscore = f(xr)"
"0","    "
"0","    if (res[1, 'score'] <= rscore & rscore < res[npar, 'score']) {"
"0","      res[nr,] = c(xr, rscore)"
"0","      next"
"0","    }"
"0","    "
"0","    # expansion"
"0","    if (rscore < res[1, 'score']) {"
"0","      xe = x0 + gamma * (xr - x0)"
"0","      escore = f(xe)"
"0","      if (escore < rscore) {"
"0","        res[nr, ] = c(xe, escore)"
"0","        next"
"0","      } else {"
"0","        res[nr, ] = c(xr, rscore)"
"0","        next"
"0","      }"
"0","    }"
"0","    "
"0","    # contraction"
"0","    xc = x0 + rho * (res[nr, -nc] - x0)"
"0","    "
"0","    cscore = f(xc)"
"0","    "
"0","    if (cscore < res[nr, 'score']) {"
"0","      res[nr,] = c(xc, cscore)"
"0","      next"
"0","    }"
"0","    "
"0","    # reduction"
"0","    x1 = res[1, -nc]"
"0","    "
"0","    nres = res"
"0","    "
"0","    for (i in 1:nr) {"
"0","      redx  = x1 + sigma * (res[i, -nc] - x1)"
"0","      score = f(redx)"
"0","      nres[i, ] = c(redx, score)"
"0","    }"
"0","    "
"0","    res = nres"
"0","  }"
"0","}"
"0",""
"0",""
"0","#' ## Example function"
"0",""
"0","f = function(x) {"
"0","  sin(x[1]) * cos(x[2]) * (1 / (abs(x[3]) + 1))"
"0","}"
"0",""
"0","nelder_mead2("
"0","  f, "
"0","  c(0, 0, 0), "
"0","  max_iter = 1000, "
"0","  no_improve_thr = 1e-12"
"0",")"
"1","        par_1 "
"1","        par_2 "
"1","        par_3 "
"1","        score "
"1","
"
"1","-1.570797e+00 "
"1","-2.235577e-07 "
"1"," 1.622809e-14 "
"1","-1.000000e+00 "
"1","
"
"0","optimx::optimx("
"0","  par = c(0, 0, 0), "
"0","  fn = f, "
"0","  method   = ""Nelder-Mead"","
"0","  control  = list("
"0","    alpha  = 1,"
"0","    gamma  = 2,"
"0","    beta   = 0.5,"
"0","    maxit  = 1000,"
"0","    reltol = 1e-12"
"0","  )"
"0",")"
"2","Avis : no non-missing arguments to max; returning -Inf"
"2","Avis : no non-missing arguments to min; returning Inf"
